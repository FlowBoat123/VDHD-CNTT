#!/usr/bin/env python3
"""
Dialogflow Intent & Entity Analyzer
PhÃ¢n tÃ­ch chi tiáº¿t intents vÃ  entities tá»« Dialogflow vá»›i chiáº¿n lÆ°á»£c sampling thÃ´ng minh
Sá»­ dá»¥ng LLM Ä‘á»ƒ hiá»ƒu má»¥c tiÃªu vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a tá»«ng intent/entity
"""

import os
import json
import random
import requests
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from google.cloud import dialogflow_v2 as dialogflow
from google.oauth2 import service_account
from dotenv import load_dotenv
from collections import defaultdict

load_dotenv()

# Paths     
DIALOGFLOW_KEY_PATH = os.getenv("DIALOGFLOW_KEY_PATH", "backend/key.json")
INTENT_ANALYSIS_PATH = "logs/dialogflow_intent_analysis.json"

# DeepSeek API
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_API_URL = os.getenv("DEEPSEEK_API_URL", "https://api.deepseek.com/v1/chat/completions")

# Load Dialogflow credentials
credentials = service_account.Credentials.from_service_account_file(DIALOGFLOW_KEY_PATH)
PROJECT_ID = json.load(open(DIALOGFLOW_KEY_PATH))['project_id']


def extract_entities_from_training_phrase(training_phrase) -> List[str]:
    """
    TrÃ­ch xuáº¥t cÃ¡c entity types Ä‘Æ°á»£c sá»­ dá»¥ng trong má»™t training phrase
    """
    entities = []
    for part in training_phrase.parts:
        if part.entity_type:
            # Láº¥y tÃªn entity type (bá» prefix náº¿u cÃ³)
            entity_type = part.entity_type.split('/')[-1]
            if entity_type.startswith('@'):
                entity_type = entity_type[1:]
            entities.append(entity_type)
    return entities


def get_training_phrase_text(training_phrase) -> str:
    """
    Láº¥y text Ä‘áº§y Ä‘á»§ tá»« training phrase
    """
    return "".join([part.text for part in training_phrase.parts])


def categorize_training_phrases_by_entities(training_phrases, required_params: List[str]) -> Dict:
    """
    PhÃ¢n loáº¡i training phrases dá»±a trÃªn entities
    
    Returns:
        {
            "missing_required": [...],  # Thiáº¿u entity báº¯t buá»™c
            "has_required": [...],      # Äá»§ entity báº¯t buá»™c
            "no_entities": [...],       # KhÃ´ng cÃ³ entity
            "sorted_by_entity_count": [...],  # Sort theo sá»‘ lÆ°á»£ng entity
        }
    """
    missing_required = []
    has_required = []
    no_entities = []
    with_entities = []
    
    required_params_set = set(required_params)
    
    for tp in training_phrases:
        entities_in_phrase = extract_entities_from_training_phrase(tp)
        entities_set = set(entities_in_phrase)
        phrase_text = get_training_phrase_text(tp)
        
        phrase_data = {
            "text": phrase_text,
            "entities": entities_in_phrase,
            "entity_count": len(entities_in_phrase)
        }
        
        if not entities_in_phrase:
            no_entities.append(phrase_data)
        else:
            # Check if has all required params
            if required_params_set and required_params_set.issubset(entities_set):
                has_required.append(phrase_data)
            elif required_params_set:
                missing_required.append(phrase_data)
            else:
                # KhÃ´ng cÃ³ required params nhÆ°ng cÃ³ entities
                with_entities.append(phrase_data)
    
    # Sort by entity count (ascending: Ã­t entity â†’ nhiá»u entity)
    sorted_by_count = sorted(with_entities, key=lambda x: x['entity_count'])
    
    return {
        "missing_required": missing_required,
        "has_required": has_required,
        "no_entities": no_entities,
        "sorted_by_entity_count": sorted_by_count
    }


def smart_sample_training_phrases(training_phrases, required_params: List[str]) -> List[Dict]:
    """
    Láº¥y training phrases theo chiáº¿n lÆ°á»£c thÃ´ng minh
    
    Quy táº¯c:
    - CÃ³ required params: 2 thiáº¿u + 3 Ä‘á»§ + 5 ngáº«u nhiÃªn
    - KhÃ´ng cÃ³ required nhÆ°ng cÃ³ entities: tá»« Ã­t â†’ nhiá»u entity (Ä‘a dáº¡ng)
    - KhÃ´ng cÃ³ entities: 10 ngáº«u nhiÃªn
    """
    categorized = categorize_training_phrases_by_entities(training_phrases, required_params)
    
    samples = []
    
    if required_params:
        # Intent cÃ³ required params
        # 2 cÃ¢u thiáº¿u required
        missing = categorized["missing_required"]
        samples.extend(random.sample(missing, min(2, len(missing))))
        
        # 3 cÃ¢u Ä‘á»§ required
        has_req = categorized["has_required"]
        samples.extend(random.sample(has_req, min(3, len(has_req))))
        
        # 5 cÃ¢u ngáº«u nhiÃªn (tá»« táº¥t cáº£)
        all_phrases = [
            {"text": get_training_phrase_text(tp), 
             "entities": extract_entities_from_training_phrase(tp),
             "entity_count": len(extract_entities_from_training_phrase(tp))}
            for tp in training_phrases
        ]
        # Loáº¡i trá»« nhá»¯ng cÃ¢u Ä‘Ã£ láº¥y
        sampled_texts = {s["text"] for s in samples}
        remaining = [p for p in all_phrases if p["text"] not in sampled_texts]
        samples.extend(random.sample(remaining, min(5, len(remaining))))
        
    elif categorized["sorted_by_entity_count"]:
        # Intent khÃ´ng cÃ³ required nhÆ°ng cÃ³ entities
        # Láº¥y tá»« Ã­t entity â†’ nhiá»u entity Ä‘á»ƒ thá»ƒ hiá»‡n Ä‘á»™ phá»©c táº¡p
        sorted_phrases = categorized["sorted_by_entity_count"]
        
        # Strategy: láº¥y Ä‘á»u tá»« Ã­t â†’ nhiá»u
        total = len(sorted_phrases)
        if total <= 10:
            samples.extend(sorted_phrases)
        else:
            # Láº¥y 10 cÃ¢u Ä‘á»u Ä‘áº·n tá»« Ã­t â†’ nhiá»u
            step = total / 10
            indices = [int(i * step) for i in range(10)]
            samples.extend([sorted_phrases[i] for i in indices])
    
    else:
        # Intent khÃ´ng cÃ³ entities
        # Láº¥y 10 ngáº«u nhiÃªn
        no_ent = categorized["no_entities"]
        samples.extend(random.sample(no_ent, min(10, len(no_ent))))
    
    return samples


def smart_sample_entity_values(entity_type) -> List[Dict]:
    """
    Láº¥y 10 entity values Ä‘a dáº¡ng Ä‘á»ƒ thá»ƒ hiá»‡n rÃµ má»¥c tiÃªu cá»§a entity
    
    Strategy:
    - Náº¿u cÃ³ synonym: láº¥y entities cÃ³ nhiá»u synonyms (thá»ƒ hiá»‡n Ä‘á»™ Ä‘a dáº¡ng)
    - Láº¥y Ä‘á»u tá»« Ä‘áº§u, giá»¯a, cuá»‘i danh sÃ¡ch
    - Æ¯u tiÃªn entities cÃ³ tÃªn dÃ i/ngáº¯n khÃ¡c nhau
    """
    entities = list(entity_type.entities)
    
    if len(entities) <= 10:
        return [{
            "value": e.value,
            "synonyms": list(e.synonyms)
        } for e in entities]
    
    # Sort by diversity (cÃ³ nhiá»u synonyms + Ä‘á»™ dÃ i value)
    scored = []
    for e in entities:
        diversity_score = len(e.synonyms) * 2 + len(e.value)
        scored.append({
            "entity": e,
            "score": diversity_score
        })
    
    # Sort descending (most diverse first)
    scored.sort(key=lambda x: x["score"], reverse=True)
    
    # Láº¥y 10 Ä‘a dáº¡ng: 5 top diverse + 5 random
    samples = []
    
    # Top 5 diverse
    top_diverse = scored[:5]
    samples.extend([{
        "value": s["entity"].value,
        "synonyms": list(s["entity"].synonyms)
    } for s in top_diverse])
    
    # 5 random tá»« pháº§n cÃ²n láº¡i
    remaining = scored[5:]
    if remaining:
        random_picks = random.sample(remaining, min(5, len(remaining)))
        samples.extend([{
            "value": s["entity"].value,
            "synonyms": list(s["entity"].synonyms)
        } for s in random_picks])
    
    return samples


def fetch_dialogflow_intents_detailed():
    """
    Fetch chi tiáº¿t intents tá»« Dialogflow vá»›i smart sampling
    """
    print("\n" + "="*70)
    print("ğŸ” FETCHING DIALOGFLOW INTENTS & ENTITIES (Smart Sampling)")
    print("="*70)
    
    intents_client = dialogflow.IntentsClient(credentials=credentials)
    entity_types_client = dialogflow.EntityTypesClient(credentials=credentials)
    parent = f"projects/{PROJECT_ID}/agent"
    
    intents_data = {}
    entity_types_data = {}
    
    # ============================================
    # STEP 1: Fetch Intents
    # ============================================
    print("\nğŸ“‹ STEP 1: Fetching Intents...")
    
    try:
        intents = intents_client.list_intents(
            request={
                "parent": parent,
                "intent_view": dialogflow.IntentView.INTENT_VIEW_FULL
            }
        )
        
        for intent in intents:
            intent_name = intent.display_name
            
            # Skip default intents
            if intent_name in ["Default Fallback Intent", "Default Welcome Intent", "default_fallback"]:
                continue
            
            print(f"\n  ğŸ¯ Processing: {intent_name}")
            
            # Extract required parameters
            required_params = []
            all_params = []
            
            for param in intent.parameters:
                param_info = {
                    "name": param.display_name,
                    "entity_type": param.entity_type_display_name,
                    "required": param.mandatory
                }
                all_params.append(param_info)
                
                if param.mandatory:
                    # Láº¥y entity type name (bá» @ náº¿u cÃ³)
                    entity_type_name = param.entity_type_display_name
                    if entity_type_name.startswith('@'):
                        entity_type_name = entity_type_name[1:]
                    required_params.append(entity_type_name)
            
            # Smart sampling training phrases
            training_phrases_list = list(intent.training_phrases)
            sampled_phrases = smart_sample_training_phrases(
                training_phrases_list, 
                required_params
            )
            
            print(f"     Total training phrases: {len(training_phrases_list)}")
            print(f"     Required params: {required_params}")
            print(f"     Sampled: {len(sampled_phrases)} phrases")
            
            # Display sample distribution
            if required_params:
                missing_count = sum(1 for p in sampled_phrases 
                                   if not set(required_params).issubset(set(p.get("entities", []))))
                has_count = len(sampled_phrases) - missing_count
                print(f"       â†’ {missing_count} missing required, {has_count} has required")
            else:
                entity_counts = [p.get("entity_count", 0) for p in sampled_phrases]
                if entity_counts and max(entity_counts) > 0:
                    print(f"       â†’ Entity counts: {min(entity_counts)} to {max(entity_counts)}")
                else:
                    print(f"       â†’ No entities")
            
            intents_data[intent_name] = {
                "display_name": intent_name,
                "action": intent.action or "",
                "parameters": all_params,
                "required_parameters": required_params,
                "total_training_phrases": len(training_phrases_list),
                "sampled_training_phrases": sampled_phrases,
                "sampling_strategy": "smart"
            }
        
        print(f"\n  âœ… Fetched {len(intents_data)} intents")
        
    except Exception as e:
        print(f"  âŒ Error fetching intents: {e}")
        return None
    
    # ============================================
    # STEP 2: Fetch Entity Types
    # ============================================
    print("\nğŸ“‹ STEP 2: Fetching Entity Types...")
    
    try:
        entity_types = entity_types_client.list_entity_types(request={"parent": parent})
        
        for et in entity_types:
            entity_name = et.display_name
            
            print(f"\n  ğŸ·ï¸  Processing: {entity_name}")
            
            # Smart sampling entity values
            sampled_entities = smart_sample_entity_values(et)
            
            print(f"     Total entities: {len(et.entities)}")
            print(f"     Sampled: {len(sampled_entities)} entities")
            
            # Show diversity
            with_synonyms = sum(1 for e in sampled_entities if e["synonyms"])
            print(f"       â†’ {with_synonyms} entities with synonyms")
            
            entity_types_data[entity_name] = {
                "display_name": entity_name,
                "kind": et.kind.name,
                "total_entities": len(et.entities),
                "sampled_entities": sampled_entities,
                "sampling_strategy": "diverse"
            }
        
        print(f"\n  âœ… Fetched {len(entity_types_data)} entity types")
        
    except Exception as e:
        print(f"  âŒ Error fetching entity types: {e}")
    
    return {
        "intents": intents_data,
        "entity_types": entity_types_data
    }


def call_llm_analyze_intent(intent_name: str, intent_data: Dict) -> Dict:
    """
    Gá»i LLM Ä‘á»ƒ phÃ¢n tÃ­ch má»¥c tiÃªu vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a intent
    """
    if not DEEPSEEK_API_KEY:
        return {"goal": "N/A", "characteristics": [], "reasoning": "API not configured"}
    
    # Build prompt
    params_desc = "\n".join([
        f"  - {p['name']} (@{p['entity_type']}) {'[Báº®T BUá»˜C]' if p['required'] else '[tÃ¹y chá»n]'}"
        for p in intent_data["parameters"]
    ])
    
    phrases_desc = "\n".join([
        f"  - \"{p['text']}\" (entities: {', '.join(p.get('entities', [])) or 'none'})"
        for p in intent_data["sampled_training_phrases"][:10]
    ])
    
    prompt = f"""PhÃ¢n tÃ­ch Intent trong há»‡ thá»‘ng chatbot gá»£i Ã½ phim.

**Intent:** {intent_name}

**Parameters:**
{params_desc if params_desc else "  (KhÃ´ng cÃ³ parameters)"}

**Training Phrases Examples:**
{phrases_desc}

---

**Nhiá»‡m vá»¥:** PhÃ¢n tÃ­ch Äáº¶C ÄIá»‚M vÃ  Má»¤C TIÃŠU cá»§a intent nÃ y.

Tráº£ vá» JSON:
{{
    "goal": "Má»¥c tiÃªu chÃ­nh cá»§a intent (1-2 cÃ¢u ngáº¯n gá»n)",
    "characteristics": [
        "Äáº·c Ä‘iá»ƒm 1: MiÃªu táº£ cÃ¡ch user thÆ°á»ng há»i",
        "Äáº·c Ä‘iá»ƒm 2: ThÃ´ng tin nÃ o lÃ  báº¯t buá»™c/tÃ¹y chá»n",
        "Äáº·c Ä‘iá»ƒm 3: Context/tÃ¬nh huá»‘ng sá»­ dá»¥ng"
    ],
    "key_patterns": [
        "Pattern 1: Máº«u cÃ¢u Ä‘áº·c trÆ°ng",
        "Pattern 2: Tá»« khÃ³a quan trá»ng"
    ],
    "entity_usage": "CÃ¡ch sá»­ dá»¥ng entities trong intent nÃ y",
    "examples_fit_score": {{
        "high_quality": ["example 1", "example 2"],
        "medium_quality": ["example 3"],
        "reasoning": "Táº¡i sao examples nÃ y phÃ¹ há»£p/khÃ´ng phÃ¹ há»£p"
    }},
    "matching_criteria": "TiÃªu chÃ­ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¢u há»i má»›i cÃ³ khá»›p intent nÃ y (Ä‘iá»ƒm máº¡nh, Ä‘iá»ƒm yáº¿u)"
}}"""

    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers={
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch Dialogflow Intent. LUÃ”N tráº£ vá» JSON há»£p lá»‡."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2,
                "max_tokens": 800,
                "response_format": {"type": "json_object"}
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            return json.loads(content)
        else:
            print(f"    âš ï¸ LLM API error: {response.status_code}")
            return {"goal": "Error", "characteristics": []}
    
    except Exception as e:
        print(f"    âŒ Error calling LLM: {e}")
        return {"goal": "Error", "characteristics": []}


def call_llm_analyze_entity(entity_name: str, entity_data: Dict) -> Dict:
    """
    Gá»i LLM Ä‘á»ƒ phÃ¢n tÃ­ch má»¥c tiÃªu vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a entity type
    """
    if not DEEPSEEK_API_KEY:
        return {"goal": "N/A", "characteristics": [], "reasoning": "API not configured"}
    
    # Build prompt - escape special characters
    entities_desc_list = []
    for e in entity_data["sampled_entities"][:10]:
        # Escape quotes and backslashes in value and synonyms
        safe_value = e['value'].replace('\\', '\\\\').replace('"', '\\"').replace('\n', ' ')
        safe_synonyms = [s.replace('\\', '\\\\').replace('"', '\\"').replace('\n', ' ') 
                        for s in e['synonyms'][:3]]
        
        if safe_synonyms:
            entities_desc_list.append(f'  - "{safe_value}" (synonyms: {", ".join(safe_synonyms)})')
        else:
            entities_desc_list.append(f'  - "{safe_value}" (no synonyms)')
    
    entities_desc = "\n".join(entities_desc_list)
    
    prompt = f"""PhÃ¢n tÃ­ch Entity Type trong há»‡ thá»‘ng chatbot gá»£i Ã½ phim.

**Entity Type:** @{entity_name}
**Kind:** {entity_data['kind']}
**Total Values:** {entity_data['total_entities']}

**Sample Values:**
{entities_desc}

---

**Nhiá»‡m vá»¥:** PhÃ¢n tÃ­ch Má»¤C TIÃŠU vÃ  Äáº¶C ÄIá»‚M cá»§a entity type nÃ y trong chatbot.

Tráº£ vá» JSON:
{{
    "goal": "Má»¥c tiÃªu/vai trÃ² cá»§a entity type nÃ y trong chatbot (1-2 cÃ¢u)",
    "characteristics": [
        "Äáº·c Ä‘iá»ƒm 1: Kiá»ƒu dá»¯ liá»‡u (genre, person, date, rating, etc.)",
        "Äáº·c Ä‘iá»ƒm 2: Äá»™ Ä‘a dáº¡ng (cÃ³ nhiá»u synonyms? chuáº©n hÃ³a?)",
        "Äáº·c Ä‘iá»ƒm 3: Use cases"
    ],
    "value_patterns": [
        "Pattern 1: Äá»‹nh dáº¡ng giÃ¡ trá»‹",
        "Pattern 2: Synonyms strategy"
    ],
    "usage_context": "Context nÃ o entity nÃ y thÆ°á»ng xuáº¥t hiá»‡n",
    "matching_strategy": "CÃ¡ch match user input vá»›i entity values (exact, fuzzy, synonyms, etc.)"
}}"""

    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers={
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch Dialogflow Entity. LUÃ”N tráº£ vá» JSON há»£p lá»‡."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2,
                "max_tokens": 600,
                "response_format": {"type": "json_object"}
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            return json.loads(content)
        else:
            print(f"    âš ï¸ LLM API error: {response.status_code}")
            return {"goal": "Error", "characteristics": []}
    
    except json.JSONDecodeError as e:
        print(f"    âŒ JSON decode error: {e}")
        print(f"    ğŸ“ Entity: @{entity_name}")
        return {"goal": "JSON Parse Error", "characteristics": []}
    except Exception as e:
        print(f"    âŒ Error calling LLM: {e}")
        return {"goal": "Error", "characteristics": []}


def analyze_all_intents_and_entities():
    """
    Main function: Fetch + Analyze all intents and entities
    """
    print("\n" + "="*70)
    print("ğŸš€ DIALOGFLOW INTENT & ENTITY ANALYZER")
    print("="*70)
    
    # Step 1: Fetch data
    dialogflow_data = fetch_dialogflow_intents_detailed()
    
    if not dialogflow_data:
        print("âŒ Failed to fetch Dialogflow data")
        return
    
    # Step 2: Analyze intents with LLM
    print("\n" + "="*70)
    print("ğŸ§  STEP 3: Analyzing Intents with LLM...")
    print("="*70)
    
    intents_analysis = {}
    for i, (intent_name, intent_data) in enumerate(dialogflow_data["intents"].items(), 1):
        print(f"\n  [{i}/{len(dialogflow_data['intents'])}] Analyzing: {intent_name}")
        
        analysis = call_llm_analyze_intent(intent_name, intent_data)
        
        intents_analysis[intent_name] = {
            **intent_data,
            "llm_analysis": analysis
        }
        
        print(f"     âœ“ Goal: {analysis.get('goal', 'N/A')[:60]}...")
    
    # Step 3: Analyze entities with LLM
    print("\n" + "="*70)
    print("ğŸ§  STEP 4: Analyzing Entity Types with LLM...")
    print("="*70)
    
    entities_analysis = {}
    for i, (entity_name, entity_data) in enumerate(dialogflow_data["entity_types"].items(), 1):
        print(f"\n  [{i}/{len(dialogflow_data['entity_types'])}] Analyzing: @{entity_name}")
        
        analysis = call_llm_analyze_entity(entity_name, entity_data)
        
        entities_analysis[entity_name] = {
            **entity_data,
            "llm_analysis": analysis
        }
        
        print(f"     âœ“ Goal: {analysis.get('goal', 'N/A')[:60]}...")
    
    # Step 4: Save results
    output = {
        "metadata": {
            "analyzed_at": datetime.now().isoformat(),
            "project_id": PROJECT_ID,
            "total_intents": len(intents_analysis),
            "total_entity_types": len(entities_analysis)
        },
        "intents": intents_analysis,
        "entity_types": entities_analysis
    }
    
    with open(INTENT_ANALYSIS_PATH, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print("\n" + "="*70)
    print(f"âœ… ANALYSIS COMPLETE!")
    print("="*70)
    print(f"\nğŸ“„ Saved to: {INTENT_ANALYSIS_PATH}")
    print(f"   ğŸ“Š {len(intents_analysis)} intents analyzed")
    print(f"   ğŸ·ï¸  {len(entities_analysis)} entity types analyzed")
    print("\nğŸ’¡ Use this data to:")
    print("   - Evaluate new queries against intent goals")
    print("   - Score intent matching based on characteristics")
    print("   - Understand entity usage patterns")
    print("="*70)
    
    return output


# ...existing code...

def evaluate_query_against_intents(query: str, analysis_data: Dict = None) -> Dict:  # âœ¨ FIX: Return Dict
    """
    ÄÃ¡nh giÃ¡ cÃ¢u há»i má»›i vá»›i cÃ¡c intents Ä‘Ã£ phÃ¢n tÃ­ch
    """
    if analysis_data is None:
        if not os.path.exists(INTENT_ANALYSIS_PATH):
            print("âš ï¸ No analysis data found. Running analysis first...")
            try:
                analysis_data = analyze_all_intents_and_entities()
                if not analysis_data:
                    return {"top_matches": [], "overall_analysis": "Failed to analyze intents"}
            except Exception as e:
                print(f"âŒ Error running analysis: {e}")
                return {"top_matches": [], "overall_analysis": f"Error: {str(e)}"}
        else:
            with open(INTENT_ANALYSIS_PATH, 'r', encoding='utf-8') as f:
                print("ğŸ“„ Loading analysis data from file...")
                analysis_data = json.load(f)
    
    intents = analysis_data.get("intents", {})
    
    if not DEEPSEEK_API_KEY:
        print("âš ï¸ DEEPSEEK_API_KEY not configured")
        return {"top_matches": [], "overall_analysis": "API key not configured"}
    
    if not intents:
        print("âš ï¸ No intents found in analysis data")
        return {"top_matches": [], "overall_analysis": "No intents configured"}
    
    # âœ¨ FIX: Build context vá»›i proper escaping - láº¥y thÃ´ng tin chi tiáº¿t tá»« llm_analysis
    intents_summary = []
    for intent_name, intent_info in intents.items():
        llm_analysis = intent_info.get("llm_analysis", {})
        
        # Láº¥y thÃ´ng tin chi tiáº¿t tá»« llm_analysis
        goal = llm_analysis.get('goal', 'N/A')
        characteristics = llm_analysis.get('characteristics', [])
        key_patterns = llm_analysis.get('key_patterns', [])
        matching_criteria = llm_analysis.get('matching_criteria', '')
        
        # Láº¥y high quality examples tá»« examples_fit_score
        examples_fit_score = llm_analysis.get('examples_fit_score', {})
        high_quality_examples = examples_fit_score.get('high_quality', [])
        
        # Fallback: náº¿u khÃ´ng cÃ³ high_quality_examples, láº¥y tá»« sampled_training_phrases
        if not high_quality_examples:
            sampled = intent_info.get('sampled_training_phrases', [])[:3]
            high_quality_examples = [p['text'] for p in sampled]
        
        # Build intent summary vá»›i thÃ´ng tin Ä‘áº§y Ä‘á»§
        intent_summary = {
            "intent": intent_name,
            "goal": goal,
            "characteristics": characteristics[:2] if len(characteristics) > 2 else characteristics,  # Láº¥y 2 Ä‘áº·c Ä‘iá»ƒm quan trá»ng nháº¥t
            "key_patterns": key_patterns,
            "examples": high_quality_examples[:3],  # Top 3 examples cháº¥t lÆ°á»£ng cao
            "matching_criteria": matching_criteria,
            "required_params": intent_info.get('required_parameters', [])
        }
        
        intents_summary.append(intent_summary)
    
    # âœ¨ FIX: Improved prompt vá»›i context Ä‘áº§y Ä‘á»§
    prompt_context = []
    for idx, intent_sum in enumerate(intents_summary, 1):
        intent_block = f"""
Intent {idx}: {intent_sum['intent']}
- Má»¥c tiÃªu: {intent_sum['goal']}
- Äáº·c Ä‘iá»ƒm chÃ­nh:
  {chr(10).join(['  â€¢ ' + c for c in intent_sum.get('characteristics', [])])}
- Key patterns: {', '.join(intent_sum.get('key_patterns', []))}
- Examples: {', '.join([f'"{ex}"' for ex in intent_sum.get('examples', [])])}
- Matching criteria: {intent_sum.get('matching_criteria', 'N/A')}
- Required params: {', '.join(intent_sum.get('required_params', [])) or 'None'}
"""
        prompt_context.append(intent_block.strip())
    
    prompt = f"""Classify user query into one of the available intents based on detailed analysis.

Query: "{query}"

Available Intents:
{''.join([f'\n{ctx}\n---' for ctx in prompt_context])}

Task:
1. Analyze the query semantically based on intent goals and characteristics
2. Match against key patterns and examples
3. Consider matching criteria for each intent
4. Score each match (0-100) based on:
   - Goal alignment (40%)
   - Pattern match (30%)
   - Example similarity (20%)
   - Required params presence (10%)

Return JSON with top 3 intents (score > 30):
{{
    "top_matches": [
        {{
            "intent": "intent_name",
            "score": 95,
            "reasoning": "Detailed reasoning based on goal, patterns, and examples",
            "missing_info": "Missing required params if any",
            "confidence": "high/medium/low"
        }}
    ],
    "overall_analysis": "Brief semantic analysis of the query"
}}

Sort by score descending. Return ONLY valid JSON."""

    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers={
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "You are an intent classifier. ALWAYS return valid JSON only."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2,
                "max_tokens": 600,
                "response_format": {"type": "json_object"}
            },
            timeout=30
        )
        
        print(f"DeepSeek API response status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            
            # âœ¨ FIX: Better JSON parsing with error handling
            try:
                result = json.loads(content)
                
                # Validate structure
                if not isinstance(result, dict):
                    raise ValueError("Response is not a dict")
                
                if "top_matches" not in result:
                    result["top_matches"] = []
                
                if "overall_analysis" not in result:
                    result["overall_analysis"] = "No analysis provided"
                
                print(f"âœ… Parsed result: {len(result.get('top_matches', []))} matches")
                return result
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSON parse error: {e}")
                print(f"Raw content: {content[:200]}")
                return {
                    "top_matches": [],
                    "overall_analysis": f"JSON parse error: {str(e)}",
                    "raw_response": content[:500]
                }
        else:
            print(f"âš ï¸ LLM API error: {response.status_code}")
            print(f"Response: {response.text[:200]}")
            return {
                "top_matches": [],
                "overall_analysis": f"API error: {response.status_code}",
                "error_details": response.text[:200]
            }
    
    except requests.exceptions.Timeout:
        print("âŒ DeepSeek API timeout")
        return {"top_matches": [], "overall_analysis": "API timeout"}
    
    except Exception as e:
        print(f"âŒ Error evaluating query: {e}")
        import traceback
        traceback.print_exc()
        return {
            "top_matches": [],
            "overall_analysis": f"Error: {str(e)}"
        }

# ...existing code...

def test_query_evaluation():
    """
    Test function Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»™t sá»‘ queries máº«u
    """
    test_queries = [
        "Gá»£i Ã½ phim hÃ nh Ä‘á»™ng hay nhÆ° Inception",
        "TÃ´i muá»‘n xem phim tÃ¬nh cáº£m buá»“n",
        "Phim nÃ o cá»§a Leonardo DiCaprio hay nháº¥t?",
        "Cho tÃ´i xem collection phim kinh dá»‹",
        "Phim gÃ¬ Ä‘ang hot?"
    ]
    
    print("\n" + "="*70)
    print("ğŸ§ª TESTING QUERY EVALUATION")
    print("="*70)
    
    for query in test_queries:
        print(f"\nğŸ“ Query: {query}")
        result = evaluate_query_against_intents(query)
        
        print(f"\n   {result.get('overall_analysis', 'N/A')}")
        print(f"\n   Top Matches:")
        for match in result.get('top_matches', []):
            print(f"     ğŸ¯ {match['intent']} (score: {match['score']}, confidence: {match['confidence']})")
            print(f"        â†’ {match['reasoning']}")
            if match.get('missing_info'):
                print(f"        âš ï¸ Missing: {match['missing_info']}")


if __name__ == "__main__":
    # Run full analysis
    analysis_data = analyze_all_intents_and_entities()
    
    # Test evaluation
    if analysis_data:
        print("\n" + "="*70)
        input("Press Enter to run test query evaluation...")
        test_query_evaluation()
